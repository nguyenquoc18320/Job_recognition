{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "job_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8ku1e4Oib4K",
        "outputId": "204ec60a-bca8-415b-bf67-e4f94813156f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm3qsF82smow"
      },
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "use_GPU = 0\n",
        "if use_GPU:\n",
        " \tphysical_devices = tf.config.list_physical_devices('GPU')\n",
        " \ttf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "     \n",
        "NUMBER_OF_LABELS = 10\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "CHANNELS = 3\n",
        "LOAD_MODEL = 1\n",
        "NUMBER_PATTERN_FOR_TRAINING = 250\n",
        "PERCENTAGE_OF_TRAINING_IMAGES=0.01\n",
        "\n",
        "training_path = \"/content/drive/MyDrive/job_recognition/DataSet/train\"\n",
        "MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/job_recog_modelmodel/model1.h5'\n",
        "#============================#\n",
        "#Load data#\n",
        "#============================#\n",
        "\n",
        "#====================#\n",
        "#LOAD OR CREATE MODEL#\n",
        "#====================#\n",
        "def train(X_train, y_train, X_valid, y_valid):\n",
        "    if LOAD_MODEL:\n",
        "        '''Loading model'''\n",
        "        model = keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/job_recog_model\")\n",
        "    else:\n",
        "        #create model\n",
        "        model = keras.models.Sequential([\n",
        "            keras.layers.Input(shape=((IMG_WIDTH, IMG_HEIGHT, CHANNELS))),\n",
        "            keras.layers.Conv2D(32, kernel_size=3, padding='same', activation='relu'),\n",
        "            keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.MaxPooling2D(2),\n",
        "            \n",
        "            keras.layers.Conv2D(128, kernel_size=3, padding='same', activation='relu'),\n",
        "            keras.layers.Conv2D(128, kernel_size=3, padding='same', activation='relu'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.MaxPooling2D(2),\n",
        "            \n",
        "            keras.layers.Conv2D(256, kernel_size=3, padding='same', activation='relu'),\n",
        "            keras.layers.Conv2D(256, kernel_size=3, padding='same', activation='relu'),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.MaxPooling2D(2),\n",
        "            \n",
        "            keras.layers.Flatten(),\n",
        "            keras.layers.Dense(128, activation='relu'),\n",
        "            keras.layers.Dense(64, activation='relu'),\n",
        "            keras.layers.Dense(NUMBER_OF_LABELS, activation='softmax')])\n",
        "        \n",
        "    model.summary()\n",
        "    \n",
        "    #============#\n",
        "    #TRAIN MODEL#\n",
        "    #============#\n",
        "    \n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=keras.optimizers.Adam(lr=0.01),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    #performace scheduling \n",
        "    lr_scheduling = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=5)\n",
        "    \n",
        "    save_the_best_model = keras.callbacks.ModelCheckpoint(MODEL_PATH, monitor='val_loss', save_best_only=True)\n",
        "    \n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "    #train\n",
        "    history = model.fit(np.array(X_train), np.array(y_train), epochs=30, \n",
        "                        validation_data=(np.array(X_valid), np.array(y_valid)), \n",
        "                        callbacks=[lr_scheduling, save_the_best_model, early_stopping])\n",
        "    history = history.history\n",
        "\n",
        "\n",
        "'''Loading data'''\n",
        "label_names =['chef', 'doctor', 'engineer', 'farmer', 'firefighter',\n",
        "              'judge', 'mechanic', 'pilot', 'police', 'waiter']\n",
        "\n",
        "iteration = 0\n",
        "\n",
        "while iteration*PERCENTAGE_OF_TRAINING_IMAGES<1:\n",
        "    print(\"\\nIter: \", iteration)\n",
        "    images=[]\n",
        "    labels = []\n",
        "    for folder_name in label_names:\n",
        "        folder_path = os.path.join(training_path, folder_name)\n",
        "           \n",
        "        all_images = os.listdir(folder_path)\n",
        "        for img_name in all_images[int(iteration*PERCENTAGE_OF_TRAINING_IMAGES*len(all_images))\n",
        "                                   :int((iteration+1)*PERCENTAGE_OF_TRAINING_IMAGES*len(all_images))]:\n",
        "            #get image\n",
        "            image = cv2.imread(os.path.join(folder_path, img_name))\n",
        "            # print(image)\n",
        "            # show image \n",
        "            # plt.imshow(image)\n",
        "            # plt.show() \n",
        "            \n",
        "            #check imageempty  \n",
        "            if image is None:\n",
        "                continue\n",
        "                \n",
        "            image = np.array(image)\n",
        "            image = image.reshape((IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
        "            image =image/255.0\n",
        "            images.append(image)\n",
        "            labels.append(label_names.index(folder_name))\n",
        "            \n",
        "    iteration=+1      \n",
        "    \n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(images, labels, test_size=0.2)\n",
        "    \n",
        "    train(X_train, y_train, X_valid, y_valid)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMwsmwN1xjus",
        "outputId": "7a871b3f-6690-4d23-ab22-f4e51277e724"
      },
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "use_GPU = 0\n",
        "if use_GPU:\n",
        " \tphysical_devices = tf.config.list_physical_devices('GPU')\n",
        " \ttf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "     \n",
        "NUMBER_OF_LABELS = 10\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "CHANNELS = 3\n",
        "LOAD_MODEL = 1\n",
        "NUMBER_PATTERN_FOR_TRAINING = 250\n",
        "PERCENTAGE_OF_TRAINING_IMAGES=0.25\n",
        "\n",
        "training_path = \"/content/drive/MyDrive/job_recognition/DataSet/train\"\n",
        "MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/job_recog_modelmodel/model3.h5'\n",
        "\n",
        "#============================#\n",
        "#Load data#\n",
        "#============================#\n",
        "\n",
        "#====================#\n",
        "#LOAD OR CREATE MODEL#\n",
        "#====================#\n",
        "def residual_block(input, filters, kernel_size, adaptive_layer=False):\n",
        "  '''class to represent residual architecture of resnet\n",
        "  adaptive_layer: insert adaptive layer when input size is different with output size\n",
        "  return 3 blocks'''\n",
        "\n",
        "  residual_input = input\n",
        "\n",
        "  if adaptive_layer:\n",
        "    residual_input = keras.layers.Conv2D(filters, kernel_size=1, padding='same')(residual_input)\n",
        "    residual_input = keras.layers.BatchNormalization()(residual_input)\n",
        "\n",
        "  # input = keras.layers.Conv2D(filters, kernel_size=kernel_size, \n",
        "  #                             padding = 'same')(input)\n",
        "  # input = keras.layers.BatchNormalization()(input)\n",
        "  # input = keras.layers.Activation('relu')(input)\n",
        "  \n",
        "  input = keras.layers.Conv2D(filters, kernel_size=kernel_size, \n",
        "                              padding = 'same')(input)\n",
        "  input = keras.layers.BatchNormalization()(input)\n",
        "  input = keras.layers.Activation('relu')(input)\n",
        "\n",
        "  input = keras.layers.Conv2D(filters, kernel_size=kernel_size, \n",
        "                              padding = 'same')(input)\n",
        "  input = keras.layers.BatchNormalization()(input)\n",
        "\n",
        "  input = keras.layers.Add()([input, residual_input])\n",
        "\n",
        "  input = keras.layers.Activation('relu')(input)\n",
        "  return input\n",
        "\n",
        "\n",
        "def model(load_model, filter_array):\n",
        "    '''Load or create model'''\n",
        "    if LOAD_MODEL:\n",
        "        '''Loading model'''\n",
        "        model = keras.models.load_model(MODEL_PATH)\n",
        "    else:\n",
        "        input = keras.layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "        output = keras.layers.Conv2D(64, kernel_size=3, padding='same')(input)\n",
        "        output = keras.layers.BatchNormalization()(output)\n",
        "        output = keras.layers.Activation('relu')(output)\n",
        "\n",
        "        output = keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(output)\n",
        "\n",
        "        for i in range(len(filter_array)):\n",
        "          #don't use adaptive layer\n",
        "          if filter_array[i]==filter_array[max(0, i-1)]:\n",
        "            output = residual_block(output, filter_array[i], 3, False)\n",
        "          else:\n",
        "            output = residual_block(output, filter_array[i], 3, True)\n",
        "\n",
        "        output = keras.layers.GlobalAvgPool2D()(output)\n",
        "        output = keras.layers.Dense(10)(output)\n",
        "        output = keras.layers.Activation(\"softmax\")(output)\n",
        "\n",
        "        model = keras.models.Model(inputs=[input], outputs = [output])\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def train(model, X_train, y_train, X_valid, y_valid):\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=keras.optimizers.Adam(lr=0.01),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    #performace scheduling \n",
        "    lr_scheduling = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "    \n",
        "    save_the_best_model = keras.callbacks.ModelCheckpoint(MODEL_PATH, monitor='val_loss', save_best_only=True)\n",
        "    \n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "    #train\n",
        "    history = model.fit(np.array(X_train), np.array(y_train), epochs=60, \n",
        "                        validation_data=(np.array(X_valid), np.array(y_valid)), \n",
        "                        callbacks=[lr_scheduling, save_the_best_model, early_stopping])\n",
        "    history = history.history\n",
        "\n",
        "\n",
        "'''Loading data'''\n",
        "label_names =['chef', 'doctor', 'engineer', 'farmer', 'firefighter',\n",
        "              'judge', 'mechanic', 'pilot', 'police', 'waiter']\n",
        "\n",
        "iteration = 2\n",
        "\n",
        "model = model(0, [64, 64, 128, 256, 512] )\n",
        "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)\n",
        "\n",
        "while iteration*PERCENTAGE_OF_TRAINING_IMAGES<1:\n",
        "    print(\"\\nIter: \", iteration)\n",
        "    images=[]\n",
        "    labels = []\n",
        "    for folder_name in label_names:\n",
        "        folder_path = os.path.join(training_path, folder_name)\n",
        "           \n",
        "        all_images = os.listdir(folder_path)\n",
        "        for img_name in all_images[int(iteration*PERCENTAGE_OF_TRAINING_IMAGES*len(all_images))\n",
        "                                   :int((iteration+1)*PERCENTAGE_OF_TRAINING_IMAGES*len(all_images))]:\n",
        "            #get image\n",
        "            image = cv2.imread(os.path.join(folder_path, img_name))\n",
        "            # print(image)\n",
        "            # show image \n",
        "            # plt.imshow(image)\n",
        "            # plt.show() \n",
        "            \n",
        "            #check imageempty  \n",
        "            if image is None:\n",
        "                continue\n",
        "                \n",
        "            image = np.array(image)\n",
        "            image = image.reshape((IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
        "            image =image/255.0\n",
        "            images.append(image)\n",
        "            labels.append(label_names.index(folder_name))\n",
        "            \n",
        "    iteration=iteration+1      \n",
        "    \n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(images, labels, test_size=0.2)\n",
        "    print(\"y_train: \", y_train)\n",
        "    print(\"y_valid: \", y_valid)\n",
        "    \n",
        "    train(model, X_train, y_train, X_valid, y_valid)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 224, 224, 64) 256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 224, 224, 64) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 111, 111, 64) 0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 64) 36928       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 111, 111, 64) 36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 111, 111, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 111, 111, 64) 0           batch_normalization_2[0][0]      \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 111, 111, 64) 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 111, 111, 64) 36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 111, 111, 64) 256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 111, 111, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 111, 111, 64) 36928       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 111, 111, 64) 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 111, 111, 64) 0           batch_normalization_4[0][0]      \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 111, 111, 64) 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 111, 111, 128 73856       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 111, 111, 128 512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 111, 111, 128 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 111, 111, 128 147584      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 111, 111, 128 8320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 111, 111, 128 512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 111, 111, 128 512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 111, 111, 128 0           batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 111, 111, 128 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 111, 111, 256 295168      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 111, 111, 256 1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 111, 111, 256 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 111, 111, 256 590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 111, 111, 256 33024       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 111, 111, 256 1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 111, 111, 256 1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 111, 111, 256 0           batch_normalization_10[0][0]     \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 111, 111, 256 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 111, 111, 512 1180160     activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 111, 111, 512 2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 111, 111, 512 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 111, 111, 512 2359808     activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 111, 111, 512 131584      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 111, 111, 512 2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 111, 111, 512 2048        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 111, 111, 512 0           batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 111, 111, 512 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 512)          0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           5130        global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 10)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 4,986,250\n",
            "Trainable params: 4,980,234\n",
            "Non-trainable params: 6,016\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "Iter:  2\n",
            "y_train:  [0, 5, 5, 2, 2, 4, 2, 6, 2, 7, 5, 7, 4, 5, 9, 7, 7, 5, 5, 2, 2, 8, 6, 5, 5, 6, 8, 6, 2, 3, 9, 5, 3, 5, 7, 7, 2, 4, 3, 2, 6, 9, 5, 4, 2, 8, 3, 2, 4, 5, 4, 6, 5, 4, 0, 3, 1, 1, 9, 0, 3, 8, 1, 7, 8, 0, 8, 1, 9, 5, 5, 5, 5, 4, 2, 0, 3, 6, 2, 3, 3, 4, 8, 5, 7, 5, 9, 6, 5, 0, 2, 2, 0, 6, 3, 2, 6, 1, 3, 0, 7, 7, 5, 4, 3, 4, 1, 5, 5, 8, 3, 8, 7, 4, 9, 7, 5, 2, 9, 8, 4, 0, 4, 0, 6, 5, 1, 2, 7, 4, 4, 8, 0, 8, 1, 4, 3, 0, 3, 4, 0, 8, 2, 4, 6, 9, 1, 7, 9, 3, 0, 2, 5, 8, 7, 1, 0, 8, 2, 9, 6, 0, 9, 9, 7, 9, 3, 5, 9, 1, 7, 7, 1, 7, 0, 0, 5, 8, 5, 6, 1, 2, 8, 3, 4, 0, 1, 5, 6, 3, 0, 9, 9, 4, 6, 1, 5, 1, 9, 6, 4, 3, 6, 0, 7, 5, 2, 0, 5, 0, 9, 8, 3, 9, 8, 5, 9, 5, 4, 3, 6, 9, 6, 2, 8, 9, 6, 2, 0, 8, 3, 2, 1, 4, 6, 6, 2, 7, 2, 6, 6, 9, 3, 5, 1, 2, 8, 1, 5, 1, 6, 0, 0, 2, 7, 1, 1, 2, 2, 3, 8, 9, 8, 1, 9, 0, 0, 9, 4, 8, 7, 7, 6, 4, 4, 8, 3, 5, 9, 7, 2, 9, 9, 7, 4, 7, 4, 6, 6, 4, 1, 8, 3, 9, 9, 2, 3, 1, 0, 8, 2, 1, 6, 1, 0, 6, 0, 1, 5, 5, 4, 7, 4, 5, 5, 7, 5, 9, 3, 2, 8, 4, 0, 3, 5, 1, 0, 5, 7, 6, 4, 3, 4, 4, 4, 2, 4, 8, 7, 0, 9, 8, 9, 9, 3, 7, 1, 9, 7, 2, 6, 2, 2, 6, 0, 3, 0, 4, 2, 4, 1, 6, 5, 3, 2, 4, 5, 4, 5, 1, 3, 3, 3, 2, 4, 0, 7, 4, 9, 3, 9, 2, 3, 4, 7, 3, 6, 7, 8, 0, 5, 4, 6, 5, 6, 2, 5, 3, 9, 3, 0, 7, 0, 0, 5, 7, 8, 1, 7, 0, 3, 5, 6, 3, 8, 5, 8, 1, 8, 8, 8, 0, 3, 8, 0, 2, 6, 0, 9, 5, 8, 7, 9, 9, 1, 9, 1, 4, 7, 7, 3, 8, 3, 1, 0, 5, 9, 7, 8, 2, 8, 0, 9, 6, 1, 8, 8, 1, 5, 8, 2, 8, 7, 9, 7, 4, 7, 7, 2, 0, 0, 0, 1, 8, 6, 5, 6, 7, 1, 5, 4, 8, 9, 5, 4, 2, 4, 9, 3, 8, 3, 5, 1, 3, 1, 2, 0, 1, 1, 3, 3, 3, 5, 2, 5, 6, 9, 2, 7, 8, 9, 6, 4, 5, 2, 2, 4, 2, 6, 6, 2, 5, 8, 7, 0, 8, 1, 9, 5, 8, 0, 4, 4, 7, 8, 3, 9, 9, 5, 1, 7, 7, 9, 3, 0, 3, 1, 8, 2, 0, 5, 2, 8, 6, 0, 9, 9, 2, 4, 8, 2, 0, 9, 1, 2, 3, 2, 3, 0, 2, 9, 9, 6, 3, 1, 3, 5, 0, 2, 7, 0, 1, 9, 0, 4, 3, 3, 4, 3, 7, 4, 9, 9, 8, 7, 7, 2, 6, 8, 8, 5, 9, 9, 9, 7, 7, 9, 9, 1, 5, 1, 3, 6, 9, 8, 3, 0, 6, 7, 8, 4, 2, 6, 3, 4, 4, 3, 3, 3, 2, 1, 3, 6, 1, 5, 6, 6, 4, 7, 1, 8, 1, 9, 5, 0, 6, 6, 8, 9, 9, 2, 0, 3, 1, 2, 3, 4, 9, 5, 6, 8, 2, 8, 0, 0, 8, 0, 4, 4, 8, 1, 5, 6, 3, 3, 8, 5, 8, 1, 7, 3, 6, 8, 1, 4, 7, 2, 6, 3, 2, 8, 4, 5, 4, 6, 0, 3, 3, 5, 4, 0, 4, 3, 1, 1, 6, 8, 9, 9, 7, 6, 9, 7, 7, 7, 0, 0, 2, 6, 0, 5, 1, 5, 0, 5, 6, 1, 2, 6, 1, 7, 4, 5, 7, 7, 5, 1, 0, 9, 2, 1, 9, 8, 7, 7, 8, 7, 7, 9, 7, 3, 8, 1, 3, 3, 2, 8, 0, 0, 6, 2, 8, 8, 8, 5, 8, 8, 3, 4, 5, 1, 4, 3, 1, 4, 6, 7, 6, 3, 4, 8, 9, 7, 4, 4, 7, 6, 6, 5, 8, 6, 6, 3, 9, 1, 3, 6, 5, 2, 8, 7, 8, 0, 6, 4, 1, 2, 4, 7, 7, 6, 1, 6, 5, 9, 0, 3, 7, 1, 5, 1, 0, 3, 7, 1, 5, 2, 3, 7, 3, 8, 9, 7, 9, 2, 8, 2, 6, 7, 3, 4, 9, 1, 0, 9, 4, 9, 0, 7, 2, 2, 2, 7, 7, 8, 0, 6, 9, 7, 9, 8, 7, 7, 9, 9, 6, 6, 2, 9, 9, 3, 2, 9, 1, 1, 9, 2, 3, 4, 1, 2, 7, 0, 4, 8, 6, 2, 9, 7, 0, 6, 6, 0, 3, 5, 6, 3, 0, 9, 1, 0, 3, 9, 7, 9, 1, 7, 4, 0, 2, 5, 6, 0, 9, 8, 4, 5, 8, 9, 5, 9, 9, 9, 8, 1, 8, 7, 3, 3, 4, 7, 7, 8, 4, 9, 2, 2, 3, 0, 7, 1, 9, 0, 2, 8, 0, 5, 3, 3, 7, 1, 6, 7, 5, 6, 8, 7, 6, 0, 4, 1, 5, 2, 7, 3, 6, 1, 6, 9, 5, 8, 9, 0, 8, 3, 8, 4, 5, 4, 4, 4, 1, 0, 0, 6, 9, 7, 4, 8, 8, 8, 4, 8, 8, 3, 2, 7, 3, 1, 7, 0, 2, 0, 1, 8, 7, 2, 5, 6, 0, 5, 7, 9, 3, 4, 0, 5, 6, 7, 4, 8, 3, 0, 7, 5, 0, 8, 2, 2, 5, 4, 6, 0, 7, 1, 8, 0, 7, 2, 6, 4, 7, 9, 4, 8, 8, 1, 6, 5, 6, 3, 6, 9, 0, 1, 8, 8, 3, 3, 0, 9, 4, 0, 8, 9, 6, 9, 8, 5, 6, 3, 4, 7, 0, 4, 5, 4, 1, 2, 1, 1, 1, 2, 6, 1, 9, 4, 1, 9, 8, 9, 8, 6, 8, 0, 4, 0, 1, 0, 7, 7, 2, 3, 5, 2, 6, 7, 4, 2, 4, 3, 5, 0, 3, 5, 2, 0, 8, 3, 6, 6, 8, 6, 6, 8, 0, 8, 5, 2, 2, 2, 2, 5, 9, 2, 4, 6, 2, 9, 5, 2, 8, 4, 4, 0, 8, 9, 2, 2, 1, 6, 6, 4, 5, 9, 0, 8, 2, 6, 6, 9, 3, 3, 6, 7, 8, 1, 8, 4, 7, 4, 9, 5, 4, 8, 4, 1, 3, 7, 6, 8, 9, 8, 4, 2, 5, 7, 7, 9, 8, 1, 1, 0, 5, 9, 0, 9, 8, 1, 0, 6, 9, 5, 1, 1, 6, 2, 3, 4, 5, 3, 3, 0, 2, 1, 4, 2, 5, 4, 7, 8, 1, 4, 3, 4, 5, 6, 8, 2, 4, 4, 5, 3, 0, 5, 3, 0, 0, 1, 3, 1, 2, 8, 0, 3, 0, 9, 3, 3, 6, 2, 8, 0, 7, 3, 9, 0, 8, 4, 7, 6, 5, 6, 7, 3, 7, 9, 9, 3, 0, 8, 5, 5, 9, 1, 9, 2, 1, 9, 0, 9, 3, 9, 8, 3, 1, 2, 6, 6, 5, 8, 9, 2, 7, 2, 9, 3, 8, 7, 1, 0, 0, 4, 4, 0, 4, 6, 6, 7, 6, 4, 1, 0, 5, 1, 8, 0, 2, 6, 5, 3, 2, 4, 9, 7, 7, 5, 6, 4, 5, 2, 4, 3, 4, 7, 9, 1, 2, 1, 6, 5, 2, 3, 0, 0, 4, 4, 5, 9, 4, 0, 2, 6, 6, 3, 9, 6, 6, 1, 0, 9, 5, 8, 0, 3, 7, 9, 1, 5, 7, 9, 8, 0, 4, 5, 4, 7, 1, 5, 2, 8, 3, 7, 0, 5, 5, 0, 3, 3, 2, 0, 5, 1, 1, 7, 7, 6, 5, 3, 4, 8, 0, 0, 3, 7, 7, 8, 8, 6, 3, 5, 5, 3, 3, 4, 3, 7, 9, 1, 9, 5, 8, 5, 1, 5, 4, 4, 0, 8, 6, 5, 0, 9, 7, 9, 8, 4, 8, 6, 5, 2, 1, 2, 7, 1, 5, 2, 9, 0, 1, 1, 9, 6, 6, 3, 6, 7, 5, 4, 3, 8, 0, 4, 6, 4, 3, 7, 0, 1, 1, 3, 6, 0, 3, 6, 0, 5, 5, 3, 8, 7, 8, 1, 2, 5, 2, 1, 0, 6, 3, 0, 8, 0, 1, 1, 8, 7, 2, 7, 6, 4, 7, 0, 8, 7, 1, 1, 0, 5, 4, 5, 2, 7, 5, 7, 8, 7, 6, 5, 1, 6, 5, 6, 6, 7, 3, 5, 3, 8, 2, 0, 5, 0, 3, 2, 8, 5, 1, 6, 8, 4, 9, 4, 3, 0, 5, 1, 1, 0, 3, 7, 1, 5, 5, 4, 6, 8, 9, 7, 0, 9, 5, 8, 6, 3, 7, 1, 9, 6, 5, 4, 5, 7, 1, 8, 3, 7, 3, 5, 3, 6, 3, 6, 2, 4, 3, 4, 8, 4, 3, 1, 0, 7, 2, 6, 7, 8, 2, 9, 7, 1, 7, 6, 4, 2, 0, 9, 9, 4, 0, 7, 3, 3, 1, 9, 0, 0, 4, 4, 6, 1, 0, 4, 5, 1, 2, 0, 3, 9, 6, 3, 1, 9, 1, 5, 7, 5, 9, 6, 1, 2, 5, 8, 3, 6, 6, 1, 5, 5, 6, 9, 7, 9, 0, 3, 1, 8, 4, 4, 8, 0, 6, 3, 6, 0, 5, 4, 8, 2, 8, 4, 3, 8, 2, 4, 0, 5, 0, 5, 5, 2, 2, 4, 0, 4, 5, 7, 8, 7, 2, 6, 5, 1, 1, 1, 2, 3, 5, 5, 9, 6, 3, 2, 6, 2, 7, 1, 4, 1, 5, 3, 3, 1, 1, 6, 1, 4, 1, 2, 6, 5, 1, 0, 4, 3, 5, 2, 5, 0, 9, 4, 8, 8, 5, 1, 8, 6, 6, 6, 8, 2, 8, 3, 1, 4, 0, 4, 5, 9, 4, 8, 0, 2, 1, 5, 9, 8, 4, 8, 6, 5, 0, 3, 7, 7, 3, 7, 7, 6, 9, 7, 9, 9, 5, 3, 1, 7, 0, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 0, 1, 3, 5, 9, 2, 9, 7, 1, 3, 5, 8]\n",
            "y_valid:  [0, 2, 6, 8, 8, 1, 4, 9, 2, 6, 9, 9, 1, 0, 9, 3, 2, 6, 1, 7, 0, 2, 7, 2, 2, 2, 7, 2, 1, 8, 0, 8, 1, 4, 6, 9, 8, 9, 4, 4, 1, 4, 2, 7, 0, 8, 1, 4, 3, 7, 0, 2, 9, 1, 2, 7, 2, 6, 7, 4, 6, 4, 5, 1, 0, 4, 1, 4, 7, 1, 3, 6, 2, 7, 4, 0, 7, 7, 4, 5, 3, 5, 1, 0, 8, 4, 2, 6, 2, 7, 5, 3, 0, 6, 8, 9, 0, 2, 4, 8, 2, 5, 6, 0, 9, 8, 7, 9, 3, 4, 2, 8, 6, 8, 0, 0, 3, 5, 1, 7, 2, 4, 1, 4, 4, 7, 9, 7, 9, 5, 2, 9, 0, 8, 4, 0, 8, 3, 8, 6, 1, 9, 4, 6, 0, 7, 5, 9, 3, 1, 3, 0, 4, 6, 2, 7, 6, 0, 3, 0, 8, 9, 8, 2, 6, 3, 4, 9, 1, 4, 9, 4, 0, 2, 8, 3, 8, 4, 5, 7, 2, 1, 7, 9, 6, 2, 6, 5, 2, 0, 7, 7, 0, 0, 1, 3, 1, 1, 7, 6, 5, 7, 5, 0, 2, 5, 3, 1, 1, 6, 3, 4, 6, 4, 6, 7, 2, 6, 4, 5, 6, 2, 2, 9, 7, 0, 0, 1, 1, 5, 9, 3, 1, 0, 4, 1, 7, 6, 1, 3, 8, 5, 8, 8, 6, 5, 7, 2, 9, 7, 2, 9, 1, 6, 4, 1, 9, 3, 7, 2, 9, 5, 3, 0, 6, 9, 4, 1, 8, 7, 0, 1, 2, 5, 1, 9, 0, 9, 9, 9, 9, 5, 2, 6, 4, 8, 9, 6, 5, 9, 1, 1, 8, 4, 9, 6, 3, 8, 0, 9, 4, 2, 4, 6, 9, 1, 0, 4, 2, 7, 5, 0, 6, 5, 2, 3, 0, 6, 3, 2, 7, 6, 4, 2, 7, 7, 1, 4, 6, 2, 7, 8, 6, 3, 1, 5, 9, 1, 3, 6, 4, 9, 1, 6, 0, 9, 4, 5, 0, 4, 9, 7, 1, 4, 9, 3, 4, 0, 7, 7, 8, 7, 8, 6, 2, 7, 8, 1, 3, 3, 3, 3, 2, 7, 2, 7, 2, 8, 4, 6, 8, 8, 0, 8, 6, 9, 6, 9, 2, 2, 2, 1, 6, 0, 3, 8, 5, 3, 3, 2, 7, 5, 9, 6, 1, 8, 0, 1, 0, 6, 2, 6, 2, 3, 3, 2, 9, 1, 8, 3, 8, 1, 8, 4, 5, 9, 3, 5, 5, 4, 9, 1, 9, 2, 0, 8, 5, 2, 7, 9, 7, 1, 1, 1, 3, 9, 6, 5, 7, 1]\n",
            "Epoch 1/60\n",
            "57/57 [==============================] - 177s 2s/step - loss: 1.2929 - accuracy: 0.6083 - val_loss: 4.4131 - val_accuracy: 0.2822\n",
            "Epoch 2/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.9057 - accuracy: 0.6965 - val_loss: 3.6919 - val_accuracy: 0.2600\n",
            "Epoch 3/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.8345 - accuracy: 0.7163 - val_loss: 3.2124 - val_accuracy: 0.2911\n",
            "Epoch 4/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.7617 - accuracy: 0.7285 - val_loss: 3.1330 - val_accuracy: 0.4000\n",
            "Epoch 5/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.7769 - accuracy: 0.7280 - val_loss: 2.7779 - val_accuracy: 0.4711\n",
            "Epoch 6/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.8299 - accuracy: 0.7112 - val_loss: 4.5462 - val_accuracy: 0.3200\n",
            "Epoch 7/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.7341 - accuracy: 0.7538 - val_loss: 5.2792 - val_accuracy: 0.3111\n",
            "Epoch 8/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.7137 - accuracy: 0.7492 - val_loss: 1.7407 - val_accuracy: 0.4911\n",
            "Epoch 9/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.7661 - accuracy: 0.7270 - val_loss: 4.3029 - val_accuracy: 0.3600\n",
            "Epoch 10/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.6523 - accuracy: 0.7821 - val_loss: 1.6080 - val_accuracy: 0.5222\n",
            "Epoch 11/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.6477 - accuracy: 0.7882 - val_loss: 3.8475 - val_accuracy: 0.3933\n",
            "Epoch 12/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.6931 - accuracy: 0.7557 - val_loss: 3.4934 - val_accuracy: 0.4467\n",
            "Epoch 13/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.6549 - accuracy: 0.7617 - val_loss: 2.8151 - val_accuracy: 0.3911\n",
            "Epoch 14/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.5268 - accuracy: 0.8178 - val_loss: 1.1855 - val_accuracy: 0.6333\n",
            "Epoch 15/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.4373 - accuracy: 0.8576 - val_loss: 1.7945 - val_accuracy: 0.5089\n",
            "Epoch 16/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.4207 - accuracy: 0.8614 - val_loss: 2.5238 - val_accuracy: 0.4711\n",
            "Epoch 17/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.3995 - accuracy: 0.8644 - val_loss: 2.3420 - val_accuracy: 0.4667\n",
            "Epoch 18/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.3501 - accuracy: 0.8857 - val_loss: 1.0268 - val_accuracy: 0.7022\n",
            "Epoch 19/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.2980 - accuracy: 0.9129 - val_loss: 0.9188 - val_accuracy: 0.7000\n",
            "Epoch 20/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.3017 - accuracy: 0.9121 - val_loss: 1.0478 - val_accuracy: 0.7044\n",
            "Epoch 21/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.3158 - accuracy: 0.8937 - val_loss: 1.0552 - val_accuracy: 0.7067\n",
            "Epoch 22/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.2992 - accuracy: 0.8911 - val_loss: 1.0615 - val_accuracy: 0.6667\n",
            "Epoch 23/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.2389 - accuracy: 0.9204 - val_loss: 0.9311 - val_accuracy: 0.7200\n",
            "Epoch 24/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.2346 - accuracy: 0.9317 - val_loss: 1.0093 - val_accuracy: 0.7044\n",
            "Epoch 25/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.2154 - accuracy: 0.9348 - val_loss: 1.3625 - val_accuracy: 0.6689\n",
            "Epoch 26/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1701 - accuracy: 0.9516 - val_loss: 0.8829 - val_accuracy: 0.7244\n",
            "Epoch 27/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1754 - accuracy: 0.9505 - val_loss: 0.9332 - val_accuracy: 0.7311\n",
            "Epoch 28/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1745 - accuracy: 0.9499 - val_loss: 0.8547 - val_accuracy: 0.7578\n",
            "Epoch 29/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1733 - accuracy: 0.9561 - val_loss: 0.8941 - val_accuracy: 0.7511\n",
            "Epoch 30/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1762 - accuracy: 0.9510 - val_loss: 0.8859 - val_accuracy: 0.7422\n",
            "Epoch 31/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1503 - accuracy: 0.9541 - val_loss: 0.9195 - val_accuracy: 0.7311\n",
            "Epoch 32/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1539 - accuracy: 0.9547 - val_loss: 0.8841 - val_accuracy: 0.7622\n",
            "Epoch 33/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1511 - accuracy: 0.9559 - val_loss: 0.8800 - val_accuracy: 0.7511\n",
            "Epoch 34/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1394 - accuracy: 0.9675 - val_loss: 0.8812 - val_accuracy: 0.7556\n",
            "Epoch 35/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1442 - accuracy: 0.9555 - val_loss: 0.8712 - val_accuracy: 0.7578\n",
            "Epoch 36/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1413 - accuracy: 0.9665 - val_loss: 0.8730 - val_accuracy: 0.7689\n",
            "Epoch 37/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1126 - accuracy: 0.9747 - val_loss: 0.8797 - val_accuracy: 0.7644\n",
            "Epoch 38/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1390 - accuracy: 0.9629 - val_loss: 0.8820 - val_accuracy: 0.7711\n",
            "\n",
            "Iter:  3\n",
            "y_train:  [3, 4, 0, 5, 5, 2, 6, 8, 2, 9, 3, 0, 4, 1, 2, 7, 4, 2, 5, 0, 6, 1, 1, 2, 8, 4, 2, 9, 9, 8, 0, 7, 1, 7, 4, 1, 3, 7, 7, 5, 5, 0, 1, 2, 4, 4, 0, 8, 2, 4, 2, 3, 9, 9, 8, 4, 1, 2, 9, 5, 3, 0, 0, 9, 5, 1, 7, 3, 1, 7, 3, 7, 4, 0, 3, 7, 8, 8, 4, 6, 6, 0, 4, 8, 1, 3, 5, 0, 7, 5, 3, 0, 9, 3, 4, 5, 8, 2, 7, 1, 6, 8, 0, 0, 0, 6, 3, 1, 3, 5, 7, 4, 3, 4, 8, 9, 2, 5, 4, 7, 0, 6, 9, 0, 1, 3, 3, 5, 2, 2, 8, 4, 0, 4, 8, 7, 4, 4, 6, 3, 9, 1, 5, 7, 7, 7, 2, 9, 9, 4, 5, 8, 1, 3, 9, 3, 0, 5, 1, 5, 9, 5, 3, 3, 2, 5, 8, 2, 6, 7, 0, 6, 1, 1, 4, 5, 7, 0, 7, 3, 9, 7, 1, 1, 2, 9, 7, 9, 3, 7, 4, 5, 7, 7, 0, 0, 1, 4, 5, 5, 8, 2, 1, 1, 8, 2, 1, 2, 8, 5, 6, 5, 3, 9, 6, 7, 8, 9, 7, 7, 0, 1, 7, 8, 2, 9, 0, 1, 9, 3, 0, 6, 2, 3, 0, 1, 6, 9, 7, 9, 8, 7, 9, 3, 0, 8, 2, 4, 9, 9, 8, 6, 8, 0, 2, 7, 2, 6, 5, 8, 2, 1, 4, 6, 2, 3, 1, 3, 0, 4, 7, 9, 7, 4, 4, 4, 9, 8, 2, 5, 0, 5, 6, 7, 3, 3, 3, 5, 0, 7, 8, 0, 4, 1, 3, 9, 9, 7, 9, 1, 3, 2, 2, 5, 7, 7, 1, 8, 2, 8, 2, 7, 7, 2, 0, 6, 5, 9, 1, 2, 1, 3, 7, 5, 0, 9, 5, 0, 5, 2, 5, 8, 1, 7, 9, 0, 3, 9, 8, 1, 3, 1, 3, 7, 5, 5, 4, 4, 7, 3, 6, 1, 5, 4, 2, 6, 6, 5, 2, 6, 6, 2, 5, 1, 1, 5, 0, 0, 7, 7, 2, 2, 7, 5, 5, 8, 6, 5, 2, 0, 4, 9, 3, 0, 6, 6, 5, 9, 2, 1, 1, 8, 9, 7, 2, 6, 6, 7, 1, 5, 1, 7, 2, 0, 8, 4, 3, 7, 8, 7, 0, 5, 6, 2, 9, 3, 8, 8, 1, 6, 9, 4, 5, 2, 5, 6, 0, 5, 7, 0, 4, 4, 7, 6, 2, 9, 9, 2, 9, 2, 2, 0, 5, 1, 2, 5, 4, 3, 0, 3, 3, 1, 3, 7, 6, 5, 4, 1, 1, 4, 0, 0, 9, 7, 4, 7, 7, 3, 9, 7, 3, 0, 7, 6, 8, 6, 0, 8, 7, 4, 4, 6, 1, 7, 3, 3, 0, 4, 4, 5, 6, 2, 2, 5, 3, 7, 3, 1, 4, 4, 7, 8, 9, 1, 8, 0, 2, 3, 7, 5, 6, 1, 4, 1, 8, 6, 5, 1, 5, 4, 1, 1, 5, 3, 1, 1, 5, 6, 2, 9, 9, 1, 6, 5, 0, 5, 7, 0, 8, 5, 6, 1, 3, 5, 6, 4, 6, 5, 4, 9, 4, 9, 7, 1, 2, 7, 2, 3, 7, 8, 7, 3, 1, 9, 5, 9, 9, 2, 3, 9, 3, 1, 4, 3, 9, 5, 3, 8, 2, 0, 6, 9, 3, 2, 0, 8, 8, 2, 3, 5, 6, 4, 9, 0, 7, 1, 2, 6, 9, 6, 0, 5, 6, 6, 2, 2, 2, 5, 2, 5, 9, 5, 8, 9, 6, 0, 7, 8, 9, 3, 7, 6, 7, 7, 7, 6, 5, 5, 7, 6, 7, 6, 1, 4, 2, 4, 8, 6, 7, 0, 0, 5, 1, 9, 1, 6, 0, 8, 5, 6, 0, 0, 2, 4, 6, 9, 7, 2, 9, 8, 9, 7, 2, 1, 5, 4, 3, 5, 8, 9, 1, 8, 3, 2, 9, 4, 2, 4, 6, 6, 2, 6, 4, 3, 0, 9, 1, 3, 0, 2, 0, 2, 9, 9, 9, 4, 4, 5, 0, 7, 3, 8, 9, 3, 4, 6, 3, 6, 4, 3, 4, 2, 3, 7, 6, 7, 4, 6, 3, 9, 6, 2, 0, 0, 5, 0, 6, 1, 2, 5, 2, 9, 1, 2, 2, 8, 1, 8, 9, 1, 3, 5, 0, 2, 5, 4, 6, 5, 0, 2, 7, 8, 9, 6, 7, 6, 3, 5, 6, 7, 5, 0, 0, 6, 2, 8, 8, 5, 0, 4, 2, 7, 9, 2, 1, 8, 5, 7, 5, 2, 8, 9, 7, 0, 3, 6, 8, 0, 9, 2, 1, 0, 9, 4, 3, 4, 6, 3, 4, 0, 5, 3, 2, 3, 8, 2, 9, 1, 1, 5, 0, 0, 5, 7, 3, 9, 1, 5, 3, 5, 9, 8, 6, 4, 8, 4, 5, 1, 6, 9, 9, 1, 5, 9, 2, 9, 8, 4, 1, 6, 6, 0, 8, 4, 6, 3, 3, 7, 9, 7, 6, 1, 8, 3, 8, 6, 9, 6, 5, 1, 9, 0, 1, 7, 1, 1, 8, 1, 7, 9, 2, 7, 3, 6, 3, 0, 5, 2, 1, 7, 4, 5, 6, 2, 6, 4, 6, 9, 8, 8, 5, 4, 4, 5, 7, 6, 7, 4, 6, 0, 0, 0, 0, 0, 8, 8, 1, 5, 7, 2, 8, 4, 7, 8, 3, 6, 3, 6, 6, 4, 2, 8, 8, 6, 2, 9, 4, 0, 2, 8, 3, 9, 6, 6, 6, 2, 2, 3, 1, 6, 3, 1, 5, 2, 1, 1, 6, 7, 8, 3, 1, 7, 1, 4, 7, 4, 4, 0, 0, 8, 6, 8, 3, 9, 3, 3, 9, 1, 1, 8, 4, 9, 3, 2, 5, 1, 8, 1, 9, 8, 7, 7, 0, 1, 8, 5, 7, 2, 1, 9, 7, 5, 2, 4, 6, 8, 4, 3, 9, 2, 0, 8, 7, 1, 5, 0, 6, 2, 9, 8, 5, 2, 7, 5, 0, 3, 2, 5, 3, 5, 6, 4, 1, 5, 2, 0, 8, 8, 3, 5, 0, 3, 1, 4, 0, 9, 6, 3, 1, 9, 7, 0, 2, 3, 0, 2, 1, 4, 4, 4, 3, 8, 2, 0, 8, 8, 7, 4, 5, 7, 9, 6, 6, 0, 1, 8, 7, 6, 6, 5, 0, 5, 7, 3, 8, 7, 9, 5, 3, 7, 0, 2, 2, 7, 4, 3, 2, 5, 2, 8, 4, 7, 7, 4, 2, 1, 4, 3, 1, 8, 6, 8, 8, 6, 4, 3, 5, 2, 4, 4, 6, 6, 3, 2, 9, 1, 3, 6, 4, 0, 2, 1, 8, 6, 7, 2, 9, 0, 4, 3, 7, 1, 3, 0, 7, 3, 8, 5, 8, 6, 4, 0, 5, 6, 9, 6, 7, 7, 9, 6, 4, 2, 8, 2, 8, 4, 6, 9, 4, 9, 2, 9, 9, 5, 7, 8, 7, 0, 5, 8, 6, 3, 3, 0, 8, 8, 5, 2, 0, 7, 7, 0, 3, 4, 6, 3, 1, 1, 5, 4, 0, 8, 6, 4, 2, 8, 1, 3, 7, 9, 8, 8, 8, 6, 5, 3, 8, 3, 6, 5, 1, 3, 7, 8, 7, 7, 9, 4, 2, 2, 9, 2, 4, 5, 6, 3, 4, 3, 1, 8, 5, 5, 0, 8, 4, 0, 9, 0, 2, 2, 2, 0, 9, 9, 5, 7, 5, 9, 1, 9, 5, 6, 8, 0, 3, 4, 4, 4, 1, 0, 4, 9, 3, 2, 1, 8, 6, 6, 4, 9, 9, 3, 8, 1, 1, 8, 1, 4, 0, 7, 7, 1, 9, 8, 8, 8, 5, 9, 2, 6, 1, 6, 4, 7, 5, 0, 1, 5, 3, 6, 5, 0, 2, 7, 8, 0, 5, 2, 2, 8, 0, 1, 2, 0, 7, 4, 1, 4, 3, 0, 3, 9, 9, 3, 8, 2, 9, 4, 0, 2, 7, 8, 9, 9, 8, 0, 0, 4, 8, 4, 6, 5, 7, 1, 3, 5, 7, 4, 2, 7, 8, 2, 6, 9, 3, 2, 5, 0, 6, 3, 2, 2, 1, 4, 4, 7, 8, 2, 9, 4, 3, 7, 5, 5, 8, 6, 6, 8, 7, 9, 4, 9, 7, 5, 2, 4, 1, 5, 7, 9, 5, 6, 2, 4, 9, 8, 1, 4, 7, 0, 4, 3, 2, 9, 9, 2, 7, 6, 8, 2, 5, 2, 0, 6, 1, 8, 1, 6, 5, 3, 1, 4, 0, 3, 6, 4, 4, 1, 9, 5, 3, 1, 9, 8, 3, 9, 6, 4, 8, 6, 6, 6, 6, 2, 1, 5, 0, 1, 8, 9, 9, 8, 1, 3, 5, 5, 5, 2, 8, 9, 1, 7, 1, 1, 2, 8, 8, 3, 6, 4, 9, 6, 1, 7, 6, 2, 3, 2, 6, 8, 9, 7, 5, 1, 7, 9, 3, 6, 1, 8, 4, 8, 1, 9, 7, 9, 8, 7, 6, 3, 9, 9, 9, 3, 3, 0, 6, 0, 2, 2, 5, 4, 5, 2, 8, 6, 4, 2, 8, 2, 0, 9, 6, 7, 5, 7, 9, 8, 6, 2, 7, 1, 2, 2, 8, 9, 2, 4, 6, 0, 5, 2, 1, 1, 2, 3, 7, 1, 3, 4, 0, 7, 6, 8, 1, 9, 1, 5, 4, 1, 4, 0, 3, 9, 9, 0, 2, 8, 3, 6, 3, 1, 3, 6, 6, 1, 4, 1, 3, 0, 4, 9, 0, 3, 8, 9, 9, 8, 0, 6, 4, 7, 3, 0, 4, 1, 7, 9, 0, 6, 3, 6, 1, 9, 5, 6, 2, 0, 2, 6, 3, 0, 1, 2, 7, 7, 3, 0, 7, 0, 5, 8, 0, 0, 7, 2, 1, 3, 3, 3, 5, 1, 7, 2, 4, 2, 4, 0, 6, 6, 6, 5, 3, 0, 6, 8, 5, 3, 9, 6, 3, 7, 4, 2, 4, 0, 0, 3, 9, 2, 9, 6, 0, 4, 0, 4, 6, 2, 2, 7, 7, 0, 8, 1, 8, 7, 7, 4, 3, 0, 8, 6, 2, 2, 9, 4, 6, 5, 2, 7, 9, 4, 8, 0, 6, 5, 6, 6, 3, 9, 6, 9, 8, 8, 5, 8, 5, 8, 0, 7, 7, 9, 9, 2, 1, 9, 5, 7, 7, 6, 0, 1, 4, 8, 5, 4, 9, 8, 5, 9, 4, 6, 0, 2, 0, 6, 9, 6, 5, 9, 6, 4, 2, 2, 9, 6, 0, 5, 2, 6, 1, 7, 4, 1, 3, 9, 7, 1, 9, 3, 0, 5, 2, 6, 8, 8, 7, 3, 1, 0, 3, 5, 1, 1, 5, 7, 9, 8, 7, 1, 6, 9, 1, 1, 1, 4, 7, 0, 0, 4, 3, 8, 0, 8, 5, 3, 9, 9, 8, 6]\n",
            "y_valid:  [1, 5, 6, 4, 0, 2, 8, 2, 4, 9, 3, 1, 4, 5, 3, 0, 9, 0, 8, 0, 4, 4, 3, 3, 8, 1, 6, 4, 3, 4, 1, 4, 5, 4, 3, 4, 6, 3, 1, 4, 8, 5, 5, 9, 5, 9, 8, 9, 3, 1, 8, 7, 5, 5, 0, 1, 6, 5, 5, 2, 4, 9, 8, 3, 1, 5, 7, 1, 1, 0, 5, 7, 0, 6, 8, 8, 3, 3, 5, 7, 0, 5, 8, 7, 6, 4, 5, 6, 4, 1, 2, 9, 7, 5, 7, 7, 7, 9, 0, 3, 7, 4, 7, 2, 0, 0, 4, 8, 1, 1, 5, 3, 7, 4, 8, 7, 3, 8, 5, 3, 9, 0, 0, 5, 9, 0, 8, 1, 4, 8, 5, 1, 2, 4, 5, 3, 7, 9, 3, 2, 6, 8, 8, 2, 3, 9, 5, 0, 8, 8, 9, 8, 2, 0, 4, 0, 6, 5, 7, 1, 3, 2, 9, 4, 8, 8, 4, 8, 1, 7, 4, 0, 5, 5, 3, 1, 7, 6, 1, 1, 6, 1, 9, 3, 6, 4, 8, 3, 6, 6, 4, 0, 8, 3, 8, 3, 5, 7, 7, 7, 8, 4, 0, 1, 7, 0, 2, 9, 0, 4, 9, 0, 0, 9, 4, 1, 9, 2, 3, 0, 1, 9, 2, 8, 4, 8, 1, 6, 6, 9, 2, 9, 5, 0, 1, 0, 9, 1, 3, 0, 5, 2, 4, 0, 7, 0, 7, 2, 6, 2, 2, 3, 3, 0, 3, 8, 5, 4, 5, 6, 0, 9, 9, 5, 1, 9, 1, 6, 0, 1, 5, 2, 6, 8, 7, 1, 4, 2, 4, 2, 5, 5, 6, 0, 2, 0, 9, 2, 3, 2, 1, 4, 7, 4, 8, 6, 2, 7, 1, 0, 3, 1, 2, 7, 3, 5, 4, 8, 1, 8, 6, 9, 4, 0, 4, 9, 8, 2, 3, 2, 2, 9, 3, 6, 1, 1, 4, 4, 6, 3, 8, 3, 0, 5, 0, 0, 2, 9, 6, 4, 6, 1, 5, 7, 6, 5, 8, 0, 4, 5, 2, 0, 0, 0, 2, 2, 7, 4, 0, 8, 3, 6, 1, 7, 7, 0, 9, 5, 3, 1, 7, 8, 4, 9, 0, 1, 9, 8, 3, 3, 3, 5, 8, 8, 3, 4, 2, 3, 4, 8, 1, 9, 6, 4, 5, 6, 4, 3, 4, 5, 5, 1, 3, 2, 8, 0, 5, 7, 7, 8, 6, 1, 8, 5, 4, 9, 5, 1, 7, 7, 1, 6, 8, 0, 3, 4, 6, 4, 0, 6, 6, 2, 0, 7, 8, 9, 3, 7, 7, 3, 3, 7, 4, 9, 4, 1, 9, 1, 8, 5]\n",
            "Epoch 1/60\n",
            "57/57 [==============================] - 114s 2s/step - loss: 1.3143 - accuracy: 0.6497 - val_loss: 7.9589 - val_accuracy: 0.3044\n",
            "Epoch 2/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.7852 - accuracy: 0.7244 - val_loss: 1.8839 - val_accuracy: 0.5644\n",
            "Epoch 3/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.7247 - accuracy: 0.7401 - val_loss: 1.9244 - val_accuracy: 0.5311\n",
            "Epoch 4/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.7096 - accuracy: 0.7555 - val_loss: 1.6640 - val_accuracy: 0.5756\n",
            "Epoch 5/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.6412 - accuracy: 0.7840 - val_loss: 2.0328 - val_accuracy: 0.5578\n",
            "Epoch 6/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.6132 - accuracy: 0.7900 - val_loss: 2.5057 - val_accuracy: 0.4444\n",
            "Epoch 7/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.6469 - accuracy: 0.7735 - val_loss: 1.5282 - val_accuracy: 0.5600\n",
            "Epoch 8/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.6178 - accuracy: 0.7820 - val_loss: 3.0348 - val_accuracy: 0.4444\n",
            "Epoch 9/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.5789 - accuracy: 0.7929 - val_loss: 1.1305 - val_accuracy: 0.6467\n",
            "Epoch 10/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.5507 - accuracy: 0.8071 - val_loss: 1.1867 - val_accuracy: 0.6378\n",
            "Epoch 11/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.5683 - accuracy: 0.8182 - val_loss: 1.4036 - val_accuracy: 0.6222\n",
            "Epoch 12/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.5031 - accuracy: 0.8350 - val_loss: 2.1662 - val_accuracy: 0.4444\n",
            "Epoch 13/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.4593 - accuracy: 0.8403 - val_loss: 1.1790 - val_accuracy: 0.6467\n",
            "Epoch 14/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.3158 - accuracy: 0.9040 - val_loss: 0.9219 - val_accuracy: 0.7200\n",
            "Epoch 15/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.3421 - accuracy: 0.8790 - val_loss: 0.9103 - val_accuracy: 0.7378\n",
            "Epoch 16/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.3083 - accuracy: 0.8913 - val_loss: 1.2108 - val_accuracy: 0.6711\n",
            "Epoch 17/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.3352 - accuracy: 0.8871 - val_loss: 0.8410 - val_accuracy: 0.7533\n",
            "Epoch 18/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.2731 - accuracy: 0.9068 - val_loss: 1.7659 - val_accuracy: 0.5556\n",
            "Epoch 19/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.2653 - accuracy: 0.9169 - val_loss: 1.1545 - val_accuracy: 0.6822\n",
            "Epoch 20/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.2350 - accuracy: 0.9187 - val_loss: 1.1991 - val_accuracy: 0.7089\n",
            "Epoch 21/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.2148 - accuracy: 0.9275 - val_loss: 1.0089 - val_accuracy: 0.7289\n",
            "Epoch 22/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1662 - accuracy: 0.9533 - val_loss: 0.8210 - val_accuracy: 0.7578\n",
            "Epoch 23/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.1547 - accuracy: 0.9495 - val_loss: 0.7794 - val_accuracy: 0.7556\n",
            "Epoch 24/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.1392 - accuracy: 0.9619 - val_loss: 0.9693 - val_accuracy: 0.7333\n",
            "Epoch 25/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.1230 - accuracy: 0.9761 - val_loss: 0.9383 - val_accuracy: 0.7622\n",
            "Epoch 26/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.1377 - accuracy: 0.9659 - val_loss: 1.0406 - val_accuracy: 0.7511\n",
            "Epoch 27/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.1060 - accuracy: 0.9731 - val_loss: 0.9137 - val_accuracy: 0.7667\n",
            "Epoch 28/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.0810 - accuracy: 0.9838 - val_loss: 0.8726 - val_accuracy: 0.7578\n",
            "Epoch 29/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.0714 - accuracy: 0.9890 - val_loss: 0.9633 - val_accuracy: 0.7667\n",
            "Epoch 30/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.0668 - accuracy: 0.9875 - val_loss: 0.8944 - val_accuracy: 0.7778\n",
            "Epoch 31/60\n",
            "57/57 [==============================] - 112s 2s/step - loss: 0.0733 - accuracy: 0.9867 - val_loss: 0.9179 - val_accuracy: 0.7733\n",
            "Epoch 32/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.0662 - accuracy: 0.9872 - val_loss: 0.9265 - val_accuracy: 0.7600\n",
            "Epoch 33/60\n",
            "57/57 [==============================] - 111s 2s/step - loss: 0.0570 - accuracy: 0.9907 - val_loss: 0.9238 - val_accuracy: 0.7689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZImbLEUCqPt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e422ae3-7236-49c0-c08c-4468350ea4da"
      },
      "source": [
        "'''TEST'''\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed May  5 23:41:30 2021\n",
        "\n",
        "@author: nguye\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NUMBER_OF_LABELS = 10\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "CHANNELS = 3\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/job_recognition/DataSet/test\"\n",
        "MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/job_recog_modelmodel/model3.h5'\n",
        "\n",
        "\n",
        "label_names =['chef', 'doctor', 'engineer', 'farmer', 'firefighter',\n",
        "              'judge', 'mechanic', 'pilot', 'police', 'waiter']\n",
        "\n",
        "#load model\n",
        "model = keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "#=======================#\n",
        "#Evaluate entire test set\n",
        "#=======================#\n",
        "if 1:\n",
        "    images=[]\n",
        "    labels = []\n",
        "    for folder_name in label_names:\n",
        "        folder_path = os.path.join(test_path, folder_name)\n",
        "           \n",
        "        all_images = os.listdir(folder_path)\n",
        "        for img_name in all_images:\n",
        "            #get image\n",
        "            image = cv2.imread(os.path.join(folder_path, img_name))\n",
        "            \n",
        "            #check imageempty  \n",
        "            if image is None:\n",
        "                continue\n",
        "                \n",
        "            image = np.array(image)\n",
        "\n",
        "            image = image.reshape((IMG_WIDTH, IMG_HEIGHT, CHANNELS))\n",
        "            image =image/255.0\n",
        "            images.append(image)\n",
        "            labels.append(label_names.index(folder_name))   \n",
        "\n",
        "    model.evaluate(np.array(images), np.array(labels))\n",
        "\n",
        "#=======================================#\n",
        "#for testing image gotten on the internet\n",
        "#=======================================#\n",
        "if 0:\n",
        "    folder_path = os.path.join(test_path)\n",
        "       \n",
        "    all_images = os.listdir(folder_path)\n",
        "    for img_name in all_images:\n",
        "        #get image\n",
        "        original_image = cv2.imread(os.path.join(folder_path, img_name))\n",
        "        \n",
        "        #check imageempty  \n",
        "        if original_image is None:\n",
        "            continue\n",
        "            \n",
        "        image = np.array(original_image)\n",
        "        \n",
        "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
        "        image =image/255.0\n",
        "      \n",
        "        pred = model.predict(np.array([image]))\n",
        "        name=label_names[np.argmax(pred,axis=1)[0]]\n",
        "        \n",
        "        plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(name)\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 83s 672ms/step - loss: 1.0422 - accuracy: 0.7090\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}